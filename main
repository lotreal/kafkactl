#!/usr/bin/env bash

set -uo pipefail
SSD="$( cd -P "$( dirname "$(realpath ${BASH_SOURCE[0]})" )" >/dev/null 2>&1 && pwd )"
source $SSD/lib.sh
source $(pwd)/.env

RUNENV=${RUNENV:-testing}

KAFKA_ZK=${KAFKA_ZK:-localhost:2181}
KAFKA_BS=${KAFKA_BS:-localhost:9092}
KFAKA_BIN=${KAFKA_BIN:-./kafka_2.13-2.8.0/bin}
KAFKA_URL="PLAINTEXT://$(echo ${KAFKA_BS} | sed 's/,/\\,/g')"

KUBE_CONTEXT=${KUBE_CONTEXT:-jp}

if [ $# -eq 0 ]; then
    echo $KUBE_CONTEXT
    __usage="
Example:

kafkactl connect debezium-mysql install

kafkactl connector s3 ordering install
"
    echo "$__usage"
    exit 1
fi


COMMAND=$1
ACTION=$COMMAND

if [[ "$COMMAND" == "connect" ]]; then
    CONNECT_NAME=$2
    ACTION=connect:$3
fi

if [[ "$COMMAND" == "connector" ]]; then
    CONNECT_NAME=$2
    CONNECTOR=$3-${CONNECT_NAME}-connector
    ACTION=connector:$4
fi

k8s:pod() {
    kubectl --context ${KUBE_CONTEXT} -n kafka get pod -l strimzi.io/name=${CONNECT_NAME}-connect -o jsonpath="{.items[0].metadata.name}"
}

connect:rest() {
    local method=$1
    shift
    local command="curl --silent -X ${method} localhost:8083$*"

    local pod=$(k8s:pod)
    echo "[INFO] $pod -> $command"
    kubectl --context ${KUBE_CONTEXT} -n kafka exec $pod -- $command | jq
}

connect:rest2() {
    local method=$1
    shift
    local command="curl --silent -X ${method} localhost:8083$*"

    local pod=$(k8s:pod)
    kubectl --context ${KUBE_CONTEXT} -n kafka exec $pod -- $command
}

# --------
connect:install() {
    cd ~/Entropy/lotreal/homework
    echo kubectl apply -f ./kafka/cdc-kafka/connect-${CONNECT_NAME}.${RUNENV}.yaml -n kafka --context ${KUBE_CONTEXT}
    kubectl apply -f ./kafka/cdc-kafka/connect-${CONNECT_NAME}.${RUNENV}.yaml -n kafka --context ${KUBE_CONTEXT}
}

connect:remove() {
    cd ~/Entropy/lotreal/homework
    echo kubectl delete -f ./kafka/cdc-kafka/connect-${CONNECT_NAME}.${RUNENV}.yaml -n kafka --context ${KUBE_CONTEXT}
    kubectl delete -f ./kafka/cdc-kafka/connect-${CONNECT_NAME}.${RUNENV}.yaml -n kafka --context ${KUBE_CONTEXT}
}


connect:connectors() {
    connect:rest GET /connectors
}

connect:plugins() {
    connect:rest GET /connector-plugins
}


# --------
connector:install() {
    local pod=$(k8s:pod)
    local file=./kafka/cdc-kafka/${CONNECTOR}.json
    echo "[INFO] $pod -> POST $file"
    cd ~/Entropy/lotreal/homework
    kubectl --context ${KUBE_CONTEXT} -n kafka exec $pod -- \
            curl --silent -X POST -d "$(cat $file)" \
            -H "Accept:application/json" \
            -H "Content-Type:application/json" \
            localhost:8083/connectors | jq
}

connector:update() {
    local pod=$(k8s:pod)
    local file=./kafka/cdc-kafka/${CONNECTOR}.json
    echo "[INFO] $pod -> PUT $file"
    cd ~/Entropy/lotreal/homework
    kubectl --context ${KUBE_CONTEXT} -n kafka exec $pod -- \
            curl --silent -X PUT --data "$(jq -c '.config' $file)" \
            -H "Content-Type: application/json" \
            localhost:8083/connectors/${CONNECTOR}/config | jq
}

connector:remove() {
    connect:rest DELETE /connectors/${CONNECTOR}
}

connector:status() {
    connect:rest GET /connectors/${CONNECTOR}/status
}

connector:error() {
    local pod=$(k8s:pod)
    kubectl --context ${KUBE_CONTEXT} -n kafka exec $pod -- \
            curl --silent -X GET localhost:8083/connectors/${CONNECTOR}/status \
            | jq  '.tasks[0].trace' | xargs echo -e
}

connector:config() {
    connect:rest GET /connectors/${CONNECTOR}/config
}

connector:pause() {
    connect:rest PUT /connectors/${CONNECTOR}/pause
}

connector:resume() {
    connect:rest PUT /connectors/${CONNECTOR}/resume
}

connector:restart() {
    connect:rest POST /connectors/${CONNECTOR}/restart
}

# --------
topic:info() {
    ${KAFKA_BIN}/kafka-configs.sh --bootstrap-server "$KAFKA_BS" --entity-type topics --describe --all --entity-name $1
    ${KAFKA_BIN}/kafka-topics.sh --bootstrap-server="$KAFKA_BS" --describe --topic $1
}

topic:list() {
    ${KAFKA_BIN}/kafka-topics.sh --list --zookeeper $KAFKA_ZK
}

topic:consumer() {
    ${KAFKA_BIN}/kafka-console-consumer.sh --bootstrap-server "$KAFKA_BS" --property print.key=true --property print.value=true --from-beginning --topic $1
}

topic:count() {
    ${KAFKA_BIN}/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list "$KAFKA_BS" --topic $1 --time -1
}

# --------
debug() {
    echo $KAFKA_URL
}

schemaregistry:install() {
    # helm repo add confluentinc https://confluentinc.github.io/cp-helm-charts/
    # helm repo update
    cd ~/INSTALL

    # git clone https://github.com/confluentinc/cp-helm-charts.git
    helm upgrade --install cdc-sr cp-helm-charts/charts/cp-schema-registry \
         --kube-context ${KUBE_CONTEXT} -n kafka \
         --set kafka.bootstrapServers="${KAFKA_URL}" \
         --set imageTag=6.2.0
}

shift
$ACTION $*
